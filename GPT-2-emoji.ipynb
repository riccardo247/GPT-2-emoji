{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "offchart-star-GPT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riccardo247/GPT-2-emoji/blob/main/GPT-2-emoji.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz3CbT3miEQF"
      },
      "source": [
        "**Introduction:**\n",
        "This a notebook showing how to generate emotion classification with an all in text approach.\n",
        "The model used is GPT-neo. This specific version was pretrained on the pile and on c4 (colossal dataset) for 700k steps. \n",
        "For this specific task the model was fine tuned on GoEmotion dataset.\n",
        "\n",
        "\n",
        "**Example:** Given a comment or text in input the model will complete with an emotions in one of the 27 defined in GoEmotion dataset.\n",
        "\n",
        "**Review:**\n",
        "This is a comment:Succeeds in providing a disquiet world the long-dreaded completion of the Police Academy series . \n",
        "\n",
        "emotion is:...\n",
        "\n",
        "**Remainder:**\n",
        "Remember to switch to TPU runtime. Possibly you need to log into Colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Tii5zEBFydn"
      },
      "source": [
        "**Download all needd packages**\n",
        "\n",
        "\n",
        "> package GPTNeo is needed with all the requirements\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Qe-S3h9AKpd",
        "outputId": "fb812a71-5691-4da4-888f-3645b99d5fba"
      },
      "source": [
        "#@title Setup\n",
        "%tensorflow_version 2.x\n",
        "!git clone https://github.com/EleutherAI/GPTNeo\n",
        "%cd GPTNeo\n",
        "!pip3 install -q -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GPTNeo'...\n",
            "remote: Enumerating objects: 3759, done.\u001b[K\n",
            "remote: Counting objects: 100% (291/291), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 3759 (delta 172), reused 253 (delta 148), pack-reused 3468\u001b[K\n",
            "Receiving objects: 100% (3759/3759), 1.44 MiB | 10.21 MiB/s, done.\n",
            "Resolving deltas: 100% (2172/2172), done.\n",
            "/content/GPTNeo\n",
            "\u001b[K     |████████████████████████████████| 368kB 5.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 14.4MB 230kB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 46.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4MB 35.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 37.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 29.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 32.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 45.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 32.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 58.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 10.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 36.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 286kB 44.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[?25h  Building wheel for tpunicorn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ring (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wirerope (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KgpQVa6F2K5"
      },
      "source": [
        "**Gopogle authentication** could be needed to access the Google bucket storing weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pofjb285ESuf",
        "outputId": "e335d4c4-164e-462a-fe4e-b9367ef77131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud init"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome! This command will take you through the configuration of gcloud.\n",
            "\n",
            "Settings from your current configuration [default] are:\n",
            "component_manager:\n",
            "  disable_update_check: 'True'\n",
            "compute:\n",
            "  gce_metadata_read_timeout_sec: '0'\n",
            "core:\n",
            "  account: riccardo.giacomelli@gmail.com\n",
            "\n",
            "Pick configuration to use:\n",
            " [1] Re-initialize this configuration [default] with new settings \n",
            " [2] Create a new configuration\n",
            "Please enter your numeric choice:  1\n",
            "\n",
            "Your current configuration has been set to: [default]\n",
            "\n",
            "You can skip diagnostics next time by using the following flag:\n",
            "  gcloud init --skip-diagnostics\n",
            "\n",
            "Network diagnostic detects and fixes local network connection issues.\n",
            "Reachability Check passed.\n",
            "Network diagnostic passed (1/1 checks passed).\n",
            "\n",
            "Choose the account you would like to use to perform operations for \n",
            "this configuration:\n",
            " [1] riccardo.giacomelli@gmail.com\n",
            " [2] Log in with a new account\n",
            "Please enter your numeric choice:  1\n",
            "\n",
            "You are logged in as: [riccardo.giacomelli@gmail.com].\n",
            "\n",
            "Pick cloud project to use: \n",
            " [1] bigbird-emc2\n",
            " [2] bigbird-freefly\n",
            " [3] birbird-emc2\n",
            " [4] optimum-monitor-215813\n",
            " [5] test-tpugpu\n",
            " [6] Create a new project\n",
            "Please enter numeric choice or text value (must exactly match list \n",
            "item):  \n",
            "Please enter a value between 1 and 6, or a value present in the list:  2\n",
            "\n",
            "Your current project has been set to: [bigbird-freefly].\n",
            "\n",
            "Do you want to configure a default Compute Region and Zone? (Y/n)?  n\n",
            "\n",
            "Your Google Cloud SDK is configured and ready to use!\n",
            "\n",
            "* Commands that require authentication will use riccardo.giacomelli@gmail.com by default\n",
            "* Commands will reference project `bigbird-freefly` by default\n",
            "Run `gcloud help config` to learn how to change individual settings\n",
            "\n",
            "This gcloud configuration is called [default]. You can create additional configurations if you work with multiple accounts and/or projects.\n",
            "Run `gcloud topic configurations` to learn more.\n",
            "\n",
            "Some things to try next:\n",
            "\n",
            "* Run `gcloud --help` to see the Cloud Platform services you can interact with. And run `gcloud help COMMAND` to get help on any gcloud command.\n",
            "* Run `gcloud topic --help` to learn about advanced features of the SDK like arg files and output formatting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxAK-TCzGJeS"
      },
      "source": [
        "**Configuration**\n",
        "\n",
        "\n",
        "> Remember to change running time to TPU\n",
        "\n",
        "\n",
        "\n",
        "> The following are configurations files for the model and data. They do not need to be modified\n",
        "\n",
        "\n",
        "> It is using GPT2 tokenizer\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMCzeJG8Ap1P",
        "outputId": "b8042709-c2bd-4d6f-8beb-634abf811821"
      },
      "source": [
        "%%writefile configs/GPT3_XL_emotion.json\n",
        "\n",
        "{\n",
        "    \"n_head\": 16,\n",
        "    \"n_vocab\": 50257,\n",
        "    \"embed_dropout\": 0,\n",
        "    \"lr\": 0.0002,\n",
        "    \"lr_decay\": \"cosine\",\n",
        "    \"warmup_steps\": 3000,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.95,\n",
        "    \"epsilon\": 1e-8,\n",
        "    \"opt_name\": \"adam\",\n",
        "    \"weight_decay\": 0,\n",
        "    \"train_batch_size\": 1,\n",
        "    \"attn_dropout\": 0,\n",
        "    \"train_steps\": 734136,\n",
        "    \"lr_decay_end\" : 300000,\n",
        "    \"eval_steps\": 20,\n",
        "    \"predict_steps\": 0,\n",
        "    \"res_dropout\": 0,\n",
        "    \"eval_batch_size\": 1,\n",
        "    \"predict_batch_size\": 1,\n",
        "    \"iterations\": 10,\n",
        "    \"n_embd\": 2048,\n",
        "    \"datasets\": [[\"goemotions_testpred\", null, null, null]], \n",
        "    \"model_path\": \"gs://bigbird-freefly/neo_gpt3/gpt3_XL/the-eye.eu/public/AI/gptneo-release/GPT3_XL_goemotions_2ok_3steps\",\n",
        "    \"n_ctx\": 2048,\n",
        "    \"n_layer\": 24,\n",
        "    \"scale_by_depth\": true,\n",
        "    \"scale_by_in\": false,\n",
        "    \"attention_types\" :  [[[\"global\", \"local\"],12]],\n",
        "    \"mesh_shape\": \"x:2,y:4\",\n",
        "    \"layout\" : \"batch:x,memory_length:y,embd:y\",\n",
        "    \"activation_function\": \"gelu\",\n",
        "    \"recompute_grad\": true,\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"tokens_per_mb_per_replica\": 2048,\n",
        "    \"precision\": \"bfloat16\",\n",
        "    \"padding_id\" : 50257,\n",
        "    \"eos_id\" : 50256\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting configs/GPT3_XL_emotion.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQESZkbiDjBZ",
        "outputId": "c4a53532-c74f-4e52-edfb-83dc73412769"
      },
      "source": [
        "%%writefile configs/dataset_configs/goemotions_testpred.json\n",
        "{\n",
        "    \"n_vocab\": 50257,\n",
        "    \"path\": \"gs://bigbird-freefly/goemotions/test_labels_pred//goemotions*.tfrecords\", \n",
        "    \"eval_path\": \"gs://bigbird-freefly/goemotions/train_labels_exneutral//goemotions*.tfrecords\",  \n",
        "    \"tokenizer_is_pretrained\": true,\n",
        "    \"tokenizer_path\": \"gpt2\",\n",
        "    \"eos_id\" : 50256,\n",
        "    \"padding_id\": 50257\n",
        "}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting configs/dataset_configs/goemotions_testpred.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruZbvBhRIcf8",
        "outputId": "623e8eeb-58ec-4aad-bea9-4bbaf2701cbe"
      },
      "source": [
        "!gsutil cp gs://bigbird-freefly/sst3/files/sample.py ./"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://bigbird-freefly/sst3/files/sample.py...\n",
            "- [1 files][  9.1 KiB/  9.1 KiB]                                                \n",
            "Operation completed over 1 objects/9.1 KiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vzWJi_vGZFB"
      },
      "source": [
        "**Review examples**\n",
        "\n",
        "\n",
        "> The following code cell writes to a txt a review example.  It provides emotion labelling. The text should be formatted in 2 lines as:\n",
        "\n",
        "\n",
        "> This is the review:\n",
        "...put the text of the review in this line...\n",
        "\n",
        "emotion is:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkSfy4FUJmdZ",
        "outputId": "68fa76a3-0eec-4e21-cef6-7926eab67c47"
      },
      "source": [
        "%%writefile comment-00001.txt\n",
        "This is a comment:Also feeling very inspired....i will definitely try doing the same thing\n",
        "emotion is:"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing comment-00001.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_K5dTBZA2Er",
        "outputId": "9f395e4b-e849-4ea8-b1eb-f98ddd69c832"
      },
      "source": [
        "%%writefile comment-00002.txt\n",
        "This is a comment:I've never been this sad in my life!\n",
        "emotion is:"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting comment-00002.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_JFAdT-OD3v",
        "outputId": "257501ce-1423-47d5-dd57-ae25fad13a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile comment-00003.txt\n",
        "This is a review:Ehhh, it's an opinion, it's not wrong or right, just highly unpopular and ill-informed.\n",
        "emotion is:"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing comment-00003.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES59Rca6KiTU"
      },
      "source": [
        "**Sentimen prediction:**\n",
        "The following code is running prediction for the txt file and output the result to the cell. Change the filename or create a new one\n",
        "\n",
        ">The first time it will take 10 minutes because it has to download the model weights. Second time will be 1-2 minutes. This notebook is just to show how it works but it is very slow!\n",
        "Output will be the input ending in sentiment like this:\n",
        "\n",
        "This is a comment:Your 'brother' had texted alot of girls and ended up on in Internet many times then, what a celebrity! Did everyone clap as well?\n",
        "\n",
        "emotion is: **admiration**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x2Qg1OVCdWi",
        "outputId": "2a801a74-bb72-4498-ad81-c6beeb64ad66"
      },
      "source": [
        "review_file ='comment-00002.txt'\n",
        "!python3 main.py --model GPT3_XL_emotion --steps_per_checkpoint 100 --tpu colab --predict --prompt $review_file"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-05 01:15:25.418459: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Current step 706748\n",
            "Saving config to gs://bigbird-freefly/neo_gpt3/gpt3_XL/the-eye.eu/public/AI/gptneo-release/GPT3_XL_goemotions_2ok_3steps\n",
            "2021-06-05 01:15:34.193401: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-05 01:15:34.204630: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-06-05 01:15:34.204691: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b0f6914c9aec): /proc/driver/nvidia/version does not exist\n",
            "Done!\n",
            "params = defaultdict(<function fetch_model_params.<locals>.<lambda> at 0x7feab4cbc290>, {'n_head': 16, 'n_vocab': 50257, 'embed_dropout': 0, 'lr': 0.0002, 'lr_decay': 'cosine', 'warmup_steps': 3000, 'beta1': 0.9, 'beta2': 0.95, 'epsilon': 1e-08, 'opt_name': 'adam', 'weight_decay': 0, 'train_batch_size': 1, 'attn_dropout': 0, 'train_steps': 734136, 'lr_decay_end': 300000, 'eval_steps': 20, 'predict_steps': 0, 'res_dropout': 0, 'eval_batch_size': 1, 'predict_batch_size': 1, 'iterations': 10, 'n_embd': 2048, 'datasets': [['goemotions_testpred', None, None, None]], 'model_path': 'gs://bigbird-freefly/neo_gpt3/gpt3_XL/the-eye.eu/public/AI/gptneo-release/GPT3_XL_goemotions_2ok_3steps', 'n_ctx': 2048, 'n_layer': 24, 'scale_by_depth': True, 'scale_by_in': False, 'attention_types': ['global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local'], 'mesh_shape': 'x:2,y:4', 'layout': 'batch:x,memory_length:y,embd:y', 'activation_function': 'gelu', 'recompute_grad': True, 'gradient_clipping': 1.0, 'tokens_per_mb_per_replica': 2048, 'precision': 'bfloat16', 'padding_id': 50257, 'eos_id': 50256, 'dataset_configs': {'goemotions_testpred': {'n_vocab': 50257, 'path': 'gs://bigbird-freefly/goemotions/test_labels_pred//goemotions*.tfrecords', 'eval_path': 'gs://bigbird-freefly/goemotions/train_labels_exneutral//goemotions*.tfrecords', 'tokenizer_is_pretrained': True, 'tokenizer_path': 'gpt2', 'eos_id': 50256, 'padding_id': 50257}}, 'mlm_training': False, 'causal': True, 'num_cores': 8, 'auto_layout': False, 'auto_layout_and_mesh_shape': False, 'use_tpu': True, 'gpu_ids': ['device:GPU:0'], 'steps_per_checkpoint': 100, 'predict': True, 'model': 'GPT', 'export': False, 'sampling_use_entmax': False, 'moe_layers': None, 'slow_sampling': False})\n",
            "Using config: {'_model_dir': 'gs://bigbird-freefly/neo_gpt3/gpt3_XL/the-eye.eu/public/AI/gptneo-release/GPT3_XL_goemotions_2ok_3steps', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.61.83.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.61.83.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.61.83.58:8470', '_evaluation_master': 'grpc://10.61.83.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=10, num_shards=8, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7feab4c6d310>}\n",
            "_TPUContext: eval_on_tpu True\n",
            "Predictions generated\n",
            "Querying Tensorflow master (grpc://10.61.83.58:8470) for TPU system metadata.\n",
            "2021-06-05 01:15:38.130858: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:373] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "Initializing TPU system (master: grpc://10.61.83.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "Found TPU system:\n",
            "*** Num TPU Cores: 8\n",
            "*** Num TPU Workers: 1\n",
            "*** Num TPU Cores Per Worker: 8\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 610441878369814078)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6232886910030733123)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -821301068320710904)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -5533001898594411314)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1852706509215690460)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -1781401088117070202)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -6416847086071133578)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 5057401120541892933)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6977748403331465864)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 102521469221275228)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7100805459934519138)\n",
            "Calling model_fn.\n",
            "num_cores_per_replica: 1\n",
            "computation_shape: [1, 1, 1, 1]\n",
            "num_replicas: 8\n",
            "device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "device_list = ['/job:worker/task:0/device:CPU:0']\n",
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "SimdMeshImpl init: Shape[x=2, y=4] LayoutRules{('memory_length', 'y'), ('embd', 'y'), ('batch', 'x')}\n",
            "Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7feb11215150>\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
            "Create pnum_tensor\n",
            "prediction_loop marked as finished\n",
            "Reraising captured error\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 257, in <module>\n",
            "    main(args)\n",
            "  File \"main.py\", line 184, in main\n",
            "    handle_pred_output_fn(predictions, logger, enc, params, out_name=f\"predictions_{args.sacred_id}_{current_step}\")\n",
            "  File \"/content/GPTNeo/inputs.py\", line 251, in handle_pred_output\n",
            "    for i, p in enumerate(predictions):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3153, in predict\n",
            "    rendezvous.raise_errors()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\", line 150, in raise_errors\n",
            "    six.reraise(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 703, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3147, in predict\n",
            "    yield_single_examples=yield_single_examples):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 613, in predict\n",
            "    self.config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2942, in _call_model_fn\n",
            "    config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1163, in _call_model_fn\n",
            "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3485, in _model_fn\n",
            "    dequeue_fn)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3740, in _predict_on_tpu_system\n",
            "    device_assignment=ctx.device_assignment)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/tpu/tpu.py\", line 1826, in split_compile_and_shard\n",
            "    xla_options=xla_options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/tpu/tpu.py\", line 1492, in split_compile_and_replicate\n",
            "    outputs = computation(*computation_inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3724, in multi_tpu_predict_steps_on_single_shard\n",
            "    cond, single_tpu_predict_step, inputs=inputs, name=b'loop')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/tpu/training_loop.py\", line 186, in while_loop\n",
            "    condition_wrapper, body_wrapper, inputs, name=\"\", parallel_iterations=1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n",
            "    return_same_structure)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2298, in BuildLoop\n",
            "    pred, body, original_loop_vars, loop_vars, shape_invariants)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2223, in _BuildLoop\n",
            "    body_result = body(*packed_vars_for_body)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/tpu/training_loop.py\", line 129, in body_wrapper\n",
            "    outputs = body(*(inputs + dequeue_ops))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1949, in predict_step\n",
            "    features, labels, is_export_mode=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2072, in _call_model_fn\n",
            "    estimator_spec = self._model_fn(features=features, **kwargs)\n",
            "  File \"/content/GPTNeo/model_fns.py\", line 112, in model_fn\n",
            "    lowering = mtf.Lowering(graph, {mesh: mesh_impl}, autostack=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mesh_tensorflow/ops.py\", line 728, in __init__\n",
            "    op.lower(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mesh_tensorflow/ops.py\", line 4569, in lower\n",
            "    new_slice_shape = mesh_impl.slice_shape(new_shape)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mesh_tensorflow/ops.py\", line 979, in slice_shape\n",
            "    % (tensor_shape, tensor_layout))\n",
            "ValueError: Tensor dimension size not divisible by mesh dimension size: tensor_shape=Shape[batch=1, sequence=2048] tensor_layout=TensorLayout(0, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0YnbBtXlhPA"
      },
      "source": [
        "**Run full test data prediction**\n",
        "\n",
        "> All the test set saved in a tfrecord file gs://bigbird-freefly/goemotions/test_labels_pred//\n",
        "\n",
        "\n",
        ">Prediction result will be saved in /test_pred/test_pred_full.jsonl. Running time is about 40 minutes\n",
        "\n",
        "\n",
        "\n",
        "> Som parameters are still hard-coded in the code. For example sampling temperature is set to 0. I overwrite few files here before execution\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ8KQolPnaEx",
        "outputId": "2f35ad7f-2202-4bbc-df93-d14748f010cf"
      },
      "source": [
        "!mkdir test_pred\n",
        "!gsutil cp gs://bigbird-freefly/neo_gpt3/gpt3_XL/the-eye.eu/public/AI/gptneo-release/GPT3_XL_goemotions_2ok_3steps/main_predict.py ./\n",
        "!gsutil cp gs://bigbird-freefly/neo_gpt3/gpt3_XL/the-eye.eu/public/AI/gptneo-release/GPT3_XL_goemotions_2ok_3steps/inputs.py ./"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘test_pred’: File exists\n",
            "Copying gs://bigbird-freefly/neo_gpt3/gpt3_XL/the-eye.eu/public/AI/gptneo-release/GPT3_XL_goemotions_2ok_3steps/main_predict.py...\n",
            "/ [1 files][ 11.8 KiB/ 11.8 KiB]                                                \n",
            "Operation completed over 1 objects/11.8 KiB.                                     \n",
            "Copying gs://bigbird-freefly/neo_gpt3/gpt3_XL/the-eye.eu/public/AI/gptneo-release/GPT3_XL_goemotions_2ok_3steps/inputs.py...\n",
            "/ [1 files][ 23.0 KiB/ 23.0 KiB]                                                \n",
            "Operation completed over 1 objects/23.0 KiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7kO5P3gpGVR",
        "outputId": "ebcea7e0-9e37-4755-9583-b090896c101f"
      },
      "source": [
        "%%writefile configs/GPT3_XL_emotion.json\n",
        "\n",
        "{\n",
        "    \"n_head\": 16,\n",
        "    \"n_vocab\": 50257,\n",
        "    \"embed_dropout\": 0,\n",
        "    \"lr\": 0.0002,\n",
        "    \"lr_decay\": \"cosine\",\n",
        "    \"warmup_steps\": 3000,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.95,\n",
        "    \"epsilon\": 1e-8,\n",
        "    \"opt_name\": \"adam\",\n",
        "    \"weight_decay\": 0,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"attn_dropout\": 0,\n",
        "    \"train_steps\": 734136,\n",
        "    \"lr_decay_end\" : 300000,\n",
        "    \"eval_steps\": 20,\n",
        "    \"predict_steps\": 0,\n",
        "    \"res_dropout\": 0,\n",
        "    \"eval_batch_size\": 8,\n",
        "    \"predict_batch_size\": 8,\n",
        "    \"iterations\": 10,\n",
        "    \"n_embd\": 2048,\n",
        "    \"datasets\": [[\"goemotions_testpred\", null, null, null]], \n",
        "    \"model_path\": \"gs://bigbird-freefly/neo_gpt3/gpt3_XL/the-eye.eu/public/AI/gptneo-release/GPT3_XL_goemotion_2ok_3steps\",\n",
        "    \"n_ctx\": 2048,\n",
        "    \"n_layer\": 24,\n",
        "    \"scale_by_depth\": true,\n",
        "    \"scale_by_in\": false,\n",
        "    \"attention_types\" :  [[[\"global\", \"local\"],12]],\n",
        "    \"mesh_shape\": \"x:2,y:4\",\n",
        "    \"layout\" : \"batch:x,memory_length:y,embd:y\",\n",
        "    \"activation_function\": \"gelu\",\n",
        "    \"recompute_grad\": true,\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"tokens_per_mb_per_replica\": 2048,\n",
        "    \"precision\": \"bfloat16\",\n",
        "    \"padding_id\" : 50257,\n",
        "    \"eos_id\" : 50256\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting configs/GPT3_XL_bakeoff.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7UPhtrZlf24"
      },
      "source": [
        "!python3 main_predict.py --predict --steps_per_checkpoint 200 --tpu colab --model GPT3_XL_emotion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIJrbZw9tI6R"
      },
      "source": [
        "!head ./test_pred/test_pred.jsonl"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}